#+TITLE: EECS 477 Notes
#+AUTHOR: Stephen Brennan
#+OPTIONS: tex:t
#+STARTUP: entitiespretty

* 2015-09-23 Wednesday

** MCNF: Transformations

   Have an instance of MCNF, and I want to transform it into another instance
   which is equivalent.

*** Removing lower bounds
   - If you have an arc from i to j, with b_i and b_j, with cost c_{ij}, and bounds
     (\ell_{ij}, u_{ij}).
   - Create a new arc with bounds (0, u_{ij}-\ell_{ij}), and you make node i
     b_i-\ell_{ij}, and node j has b_{j}+\ell_{ij}.
   - Essentially, this is an equivalent problem where you disregard the required
     flow.  The cost that's eliminated is constant, so the solution to this will
     be the same to the solution of the original.

*** Removing upper bounds
   - Again, you have i and j, with supply b_i/b_j, cost c_{ij}, and upper bound u_{iu}.
   - i is flowing to j, with an amount x.
   - Create a new "node" that has supply -u_{ij}.  Both i and j will flow into the
     new node.  x will still flow from node i into the new node.
   - The cost of the flow from i to the new node will be c_{ij}
   - The cost of the flow from j into the new node will be 0.
   - The supply of node i is still b_i.
   - The supply of j becomes b_j + u_{ij}.  Essentially, the flow from j to the new
     node will be u_{ij} - x, and when you subtract that from the supply, you will
     get b_{ij} + x, which is the flow from the original setup.

   Example: he's doing an example I can't draw, but functionally he's taking a
   MCNF problem with costs and upper bounds, and getting rid of all the upper
   bounds.  The process is as follows (for the whole graph):

   1. The whole network becomes a bipartite graph.  Each original node is on the
      left, and on the right there is a node for each arc in the original
      network.
   2. For each arc on the original, you connect both nodes on the left to the
      corresponding node on the right.
   3. You set the supply on the right side node to be the opposite of the upper
      bound.
   4. The "supplying" node's arc has the same cost.
   5. The "receiving" node's arc gets a cost of 0.
   6. The receiving node has its supply increased by the upper bound.

*** Node splitting

    Sometimes you try to model a LP as an MCNF?  So to make the modeling better,
    you may want to bound the amount flowing through a node (not just the net
    "supply/demand").

    1. Split the node into two: an input node containing all the edges going in,
       and an output node containing all the outgoing edges.
    2. Connect the nodes from the input to the output, set the cost to 0, and
       upper bound it by the amount of flow you'd like to allow through the
       terminal.
    3. You set the input node's demand to 0, and the output node's demand to the
       original.
    4. Congrats, you've split the node!

** Residual Network

   If you have a feasible flow going through an instance of an MCNF problem, you
   can create a new problem by changing the demands at each node to be what you
   currently have satisfied, and creating arcs to either send back what you've
   already got flowing, or to go up to the maximum flow between nodes.

   This new network is called a "residual network" since it represents the
   residual actions you can take to change the flow.  It's sort of a pivot in
   the LP or maybe the dual.  It's an action frequently taken by algorithms.

** MCNF as LP

   The MCNF is formulated as:

   - min c^T x, s.t.
   - Nx = b
   - x \ge 0

   Where x is a vector of arcs, c^T is a vector of costs for flows on each arc.
   N is the node arc incidence matrix.  Its rows are the nodes, and its columns
   are the arcs.  For arc (i,j), there is a +1 in row i, and a -1 in row j,
   assuming the flow is from i to j.

   We will call $A$ the maximal subset of rows of $N$ that are linearly
   independent.  It has full row rank.  It has at least two non-zero elements,
   which are \pm 1, in each column.  Then, we have the problem:

   - min c^T x, s.t.
   - Ax = b
   - x \ge 0

   If $A$ is unimodular, then \forall integer b, the optimal solution is an integer.
   Which means that the solution to the ILP version of the $A$ LP would be the
   same as the solution to the LP, and integer.  I guess that would be pretty
   cool.

   *Definition:* A is totally unimodular iff \forall square submatrices C of A, det C
   \in {0, \pm 1}.

   *Claim:* Totally Unimodular \to Unimodular.  (recall Unimodular is: \forall bases B
   of A, det B \in {\pm 1}.)
   *Proof:* Well, B is a non-singular square submatrix, so its determinant must
   be \pm 1.

   So, we must prove that $A$ is totally unimodular!
   - \forall C square submatrices k \times k.  We do induction on k.
   - Base case: k=1.  Each submatrix is 1 \times 1, and either contains -1, 0, or 1,
     so the determinant is either -1, 0, or 1.
   - Induction:
     - Case 1: C has a column containing all 0's \to det C = 0.
     - Case 2: in every column, there is a +1 and a -1.  If you sum up every
       row, you get 0, so the matrix is singular, and det C = 0.
     - Case 3: Anything else.  Pick a column such that you have just a +1 or a
       -1.  This is simply that entry (\pm 1), times the determinant of the
       submatrix that excludes that row and column.  By the inductive
       hypothesis, the determinant of this submatrix is \in {0, \pm 1}, so this
       means that det C is \in {0, \pm 1} as well!

    MCNF is unimodular!

* TODO 2015-09-21 Monday
* 2015-09-18 Friday

** Integrality

   When you have a ILP, it's normally NP-hard.  However, if the optimal solution
   to the LP is integral, then you have the solution in polynomial time.  Hooray
   for you.  How can you check to find out if the optimal solution is integral?
   Apparently, using a concept called *unimodularity*.

   For this part of the lecture, $A$ is a $p \times q$ matrix, with integer values,
   and $rank(A)=p$.

   *Definition:* A is unimodular iff $\forall B$ basis, $\det B = \pm 1$.

   *Theorem:* $A$ as above.  Equivalent:
   - (a) $A$ is unimodular
   - (b) \forall basic feasible solution, $Ax=b$, $x\ge 0$ s an integer. (b integer)
   - (c) $\forall B$ basis, $B^{-1}$ integer.

   This theorem is cool because it will apply for any objective function, and
   any integer $\vec{b}$.  However, unimodularity is more strict than purely
   figuring out whether a given problem has an integer solution that is optimal.

   *Proof:* (a) \to (b)
   - A basic feasible solution is $x=(x_B, x_L)$ s.t. $Bx_B = b$ and $x_L = 0$.
   - For all basic feasible solutions, we have $x_L = 0$, which is integer.  What
     about $x_B$?  Let's figure out the ith component of $x_B$.
   - Well, it turns out that by *Cramer's Rule*, $x_i = \frac{\det B_i}{\det B}$.
   - We know that $\det B_i =$ an integer (how?).
   - Since $\det B = \pm 1$, we know that $x_i$ must be an integer.  Yay (I guess).
   *Proof:* (b) \to (c)
   - basis \to $B$.
   - D_j: jth column of $B^{-1}$
   - $D_j = B^{-1} e_J$, where $e_j$ is a vector of zeros except for index $j$, which
     is 1.
   - $(d_{ij}) = B^{-1}$
   - \(a_i = \left\{ \begin{array}{ll} [-d_{ij}] & \text{ if } d_{ij} < 0 \\ 0 &
     \text{ if } d_{ij} \ge 0 \end{array} \right.\) (where [] is ceiling function).
   - This gives us a vector $\vec{a}$.
   - \(D_j + a \ge 0\)
   - \(Bx = e_j + Ba\)
   - \(x = D_j + a\) is a solution
   - \(B(B^{-1} e_j + a) = e_j + Ba\)
   - The right hand side is an integer, and \(B^{-1} e_j + a\) is apparently also an
     integer.
   - And I guess this proves it.  I'm totally lost here.
   *Proof:* (c) \to (a)
   - \(\det B \det B^{-1} = 1\)
   - This is because \(\det A \det B = \det AB\), and \(\det I = 1\).
   - So, \(\det B = \frac{1}{\det B^{-1}}\).  We know that $B$ is integer (since
     $A$ is as above, integer).
   - We also know by our assumption (c) that $B^{-1}$ is integer.  This means both
     determinants are integers, and the only values for $\det B^{-1}$ that make
     this possible are -1 and 1.
   - So, $A$ must be unimodular.

** Minimum Cost Network Flow

   Woo?

   In minimum cost network flow, I have a graph $G=(V,E)$ which is directed.  We
   now call vertices nodes, and edges arcs.  You have a source node and a sink
   node, with a certain amount of flow that needs to go through the network
   (e.g., 3 units must go out of the source, and into the sink).

   Each arc in the network from node $i$ and $j$ has a cost associated with it
   $c_{ij}$.  It also has an $\ell_{ij}$ that is a lower bound of flow, and an $u_{ij}$,
   which is an upper bound of what can flow through the arc.  The cost of a flow
   is the amount of flow through an arc times the cost of the arc.  All flows
   are nonnegative.

   The goal is to put the required amount of flow through the network, while
   minimizing the cost.  The total cost is the sum for each arc of the amount of
   flow times the $c_{ij}$ for that arc.

   The three next steps for this problem:
   1. Make in into a linear program.
   2. Find out whether it is unimodular.
   3. Figure out its dual.

* 2015-09-16 Wednesday

  Intro: we're getting to the core of the class.  :D

** Problem Setup

   Problem setup:

   - min c^T x, s.t.
   - Ax \ge b
   - x \ge 0

   Dual:

   - min b^T \pi, s.t.
   - A^T \pi \leq c
   - \pi \ge 0

** Complementary Slackness Proof

   *Definition:* x, \pi feasible are said to satisfy complementary slackness iff:

   - \(\pi_i \left( \sum_{i=1}^q a_{ij}x_{j} - b_i \right) = 0\), i=1,2,...,p, (1)
   - \(x_j \left( \sum_{i=1}^p a_{ij}x_i - c_j \right) = 0\), j=1,2,...,q, (2)

   *Theorem:* x, \pi feasible satisfy c.s. iff x, \pi are optimal.

   *Proof:* x, \pi feasible \to weak duality.
   - b^T \pi \le \pi^T A x \le c^T x
   - First, prove cs \to optimal
     - Assume x, \pi satisfy cs.
     - Sum up equation (1):
     - You actually get \(\pi^T A x - \pi^T b = 0\), or \(\pi^T A x = \pi^T b\)
     - Sum up equation (2):
     - You similarly get \(\pi^T A x = c^T x\).
     - So, you have \(\pi^T b = c^T x\).
     - This means that x and \pi are optimal.
   - Next, the other way around.
     - It's basically the same proof in reverse.
     - \(c^T x = b^T \pi\) (by strong duality)
     - Due to the weak duality inequalities, we know \(c^T x = \pi^T A x = b^T \pi\).
     - Then we can take the left and right side of the above, and take them make
       to summations:
     - \(\sum_{i=1}^p \pi_i \left(\sum_{j=1}^q a_{ij}x_j - b_i \right) = 0\)
     - (and similarly for the left side)
     - Since \pi_i \ge 0 and the inner summation also \ge 0, we know that each term
       must be equal to 0.
     - So, this proves (1), and WLOG the other half of the equation proves (2).

** Lagrangian Relaxation

   z^* = min c^T x, s.t. constraints

   - L(\pi) = min c^T x + \pi^T (b - Ax), s.t.
     - x \ge 0

   Assume \pi \ge 0.  z* \ge min c^T x + \pi^T (b - Ax), s.t. Ax\ge b, x\ge 0.  This makes
   sense because the feasible region is the same, the c^T x part is the same, and
   \pi^T (b - Ax) will be \le 0.  We can then further expand this to say that the
   right side is \ge L(\pi), since L(\pi) expands the feasible region, meaning that
   the optimum value is \le the more constrained one.

** Easily Finding the Dual

   We want to find the dual of every linear program, not just the form with
   minimization, Ax\ge{}b. and x\ge{}0.  We could switch the problem into this form.
   Let's call that plan B.  Let's do this instead:

   min c^T x s.t.
   - a_i^T x = b_i, (i\in{}M)
   - a_i^T x \ge b_i, (i\not\in{}M)
   - x_j \ge 0, (j\in{}N)
   - x_j unconstrained, (j\not\in{}N)

   Dual:

   max b^T \pi, s.t.
   - \pi_i unconstrained
   - \pi_i \ge 0
   - A_j^T \pi \le c_j
   - A_j^T \pi = c_j

   | Primal           | Dual             |
   | min              | max              |
   | c^T x             | b^T \pi             |
   | a_i^T x = b_i       | \pi_i unconstrained |
   | a_i^T x \ge b_i       | \pi_i \ge 0           |
   | x_j \ge 0           | a_j^T \pi \le c_j       |
   | x_J unconstrained | A_j^T \pi = c_j       |


   EG: min x_1 + x_2, s.t.
   - x_1 - 2x_2 = 3
   - x_1, x_2, \ge 0

   Originally, we would have transformed it into this problem: min x_1 + x_2, s.t.
   - x_1 - 2x_2 \ge 3
   - -x_1 + 2x_2 \ge -3
   - x_1, x_2 \ge 0

   Then, we get the dual from the constraints: max 3\pi_1 - 3\pi_2, s.t.
   - \pi_1 - \pi_2 \le 1
   - -2\pi_1 + 2\pi_2 \le 1
   - \pi_1, \pi_2 \ge 0

   Finally, simplify to max 3y, s.t.
   - y \le 1
   - -2y \le 1

** More Examples

   min 2x_1 + x_2, s.t.
   - x_1 + 3x_2 \ge 4   (\pi_1)
   - -x_1 + x_2 = 7   (\pi)

   Dual: max 4\pi_1 + 7\pi_2, s.t.
   - \pi_1 - \pi_2 \le 2 (x_1)
   - 3\pi_1 + \pi_2 = 1 (x_2)
   - \pi_1 \ge 0

  min x_1 + 2x_2 - 3x_3, s.t.
  - x_1 +  + x_3 = 4 (\pi_1)
  - 2x_1 - x_2 + 2x_3 \le 5
    - -2x_1 + x_2 - 2x_3 \ge -5 (\pi_2)
  - 3x_1 - 2x_2 + 3x_3 \ge 7, (\pi_3)
  - x_1, x_3 \ge 0

  \pi_1 is unconstrained, due to the equality.  \pi_2 and \pi_3 are \ge 0, due to the
  inequality.  The dual: max 4\pi_1 - 5\pi_2 + 7\pi_3, s.t.
  - \pi_1 - 2\pi_2 + 3\pi_3 \le 1 (x_1)
  - \pi_2 - 2\pi_3 = 2 (x_2)
  - \pi_1 - 2\pi_2 + 3\pi3 \le -3 (x_3)
  - \pi_2, \pi_3 \ge 0

  We'll do one with the knapsack problem, where we don't have a definite number
  of constraints/variables.

  max \sum_{j=1}^q c_j x_J, s.t.
  - \sum_{j=1}^q w_j x_j \le W
  - x_j \le 1, j=1...q
  - x_j \ge 0, j=1...q

  For the dual, we'll take the one constraint, call it \alpha, and the rest and call
  the others \pi_i

  - min W \alpha, s.t.
  - w_j \alpha + \pi_i \ge c_j
  - \alpha, \pi_i \ge 0

* 2015-09-14 Monday

** Homework Stuff

   Problem 3 had no solution.

   In problem 7, you could find many examples of optimal solutions that are
   actually convex combinations of two optimal basic solutions, which are not
   themselves basic solutions.  This is not what the question asked for.  It
   seems like the basic feasible solutions are always integer for this problem.

** Duality

   Strong Duality Theorem: I have a program of the form:

   - min c^T x, st
   - Ax \geq b
   - x \geq 0

   We also have its dual:

   - max b^T \pi, s.t.
   - A^T \pi \leq c
   - \pi \geq 0

   The differences between these are:
   - min/max
   - A becomes A^T
   - c and b are swapped
   - x becomes \pi

   We have weak duality, that b^T \pi \leq \pi^T A x \leq c^T x.

   *Strong Duality Theorem:* Suppose that the primal (or dual) has a finite,
   optimal solution.  Then, so does the dual (primal), and they have the same
   optimal objective value.

   *Proof:* WLOG, assume that the primal has a finite, optimal solution x^* (the
   primal and dual can be swapped and the proof is the same).  Also assume WLOG
   x^* is a BFS.  First, we'll take the primal and put it into standard form:

   - min c^T x, s.t.
   - Ax - Is = b
   - x, s \geq 0

   Let $\tilde{x}=(x,s)$, $\tilde{c}=(c,0)$, and $\tilde{A}=(A,-I)$.  Then we can put this in
   even nicer looking standard form:

   - \(\min \tilde{c}^T \tilde{x}\), s.t.
   - \(\tilde{A} \tilde{x} = b\)
   - \(\tilde{x} \geq 0\)

   When we write this in "canonical form" (I seriously need to study this part
   of the stuff):

   - \(\min (c_L^{\tilde{\pi}})^T \tilde{x}_L + \tilde{\pi}^T b\), s.t.
   - \(\tilde{x}_B + \tilde{A}\tilde{x}_L = \tilde{b}\)
   - \(\tilde{x}_B, \tilde{x}_L \geq 0\)

   We'll call the objective function z, so we're minimizing $z(\tilde{x})$.
   \(z(x^*)=\tilde{\pi}^T b\).  The next thing is to look at the reduced costs.  First,
   we know that \(c^{\tilde{\pi}} \geq 0\), because x^* is optimal.  Next, we know
   that \(c^{\tilde{\pi}} = \tilde{c} - \tilde{A}^T \tilde{\pi} =\):

   \begin{align*}
   c^{\tilde{\pi}} &= \tilde{c} - \tilde{A}^T \tilde{\pi} \\
      &= \begin{bmatrix} c \\ 0 \end{bmatrix} - \begin{bmatrix} A^T \\ -I \end{bmatrix} \\
      &= \begin{bmatrix} c - A^T \tilde{\pi} \\ \tilde{\pi} \end{bmatrix}
   \end{align*}

   This gives us that \(c \geq A^T \tilde{\pi}\), and \(\tilde{\pi} \geq 0\).  This
   tells us that the \(\tilde{\pi}\) is feasible in the dual.  And then, we know that
   the objective value of \(\tilde{\pi}\) in the dual is \(b^T \tilde{\pi}\), which is
   z(x^*).  We know by the weak duality theorem that no \pi can have an objective
   value greater than this, so it is an optimal solution for the dual!

** Complementary Slackness

   Let x, \pi be feasible solutions.  x, \pi satisfy complementary slackness (p+q
   equalities).

   \begin{equation}
     \pi_i \left(\sum_{j=1}^q a_{ij} x_{j} - b_i \right) = 0
   \end{equation}
   for i=1, 2, \dots, p

   \begin{equation}
     x_j \left(\sum_{i=1}^p a_{ij} \pi_i - c_j \right) = 0
   \end{equation}
   for j=1, 2, \dots, q

   Essentially, each of these are the slack variables.  So, if you look at the
   slackness in a constraint in one problem, and multiply it by the
   corresponding variable in its dual, you'll find that quantity is zero.

   If the slackness $s_i > 0$, then $\pi_i = 0$.  You can look at the $\pi_i$ as a
   "price" for how much you'd be willing to "get rid" of the constraint.  If
   your constraint is not even constraining you, you wouldn't care to get rid of
   it, and $\pi_i$ is 0.  On the flip side, if your slackness is 0, the $\pi_i$ will
   tell you /kinda/ how much you'd like to get rid of your constraint.
* 2015-09-11 Friday

  LP *canonical* form.

  \begin{align*}
    \min (c_L^{\pi})^T x_L + \pi^T b &\\
    \text{s.t. } x_B + \bar{A} x_L &= \bar{b} \\
    x_B, x_L &\geq 0 \\
    \text{where } \pi^T B &= c_B^T \\
    c^pi &= c - A^T \pi \\
  \end{align*}

  EG:

  \begin{align*}
    \min x_3 + x_4 + 7 &\\
    \text{s.t. } x_1 + 2x_3 + 3x_4 &= 1 \\
    x_2 + x_3 + 7x_4 &= 2 \\
    x_1, x_2, x_3, x_4 &\geq 0 \\
  \end{align*}

  - The basic variables are x_1 and x_2.  You can come up with a BFS by setting x_3
    and x_4 equal to 0, and reading off the values for the basic variables.

  *Thm:* BFS $\bar{x}$ is optimal iff c^\pi \geq 0.
  - *Proof:* \leftarrow last time
  - *Proof:* \to (only the non-degenerate case)

    \exists s . c_s^T < 0 \to $\bar{x}$ is not optimal.

    Look at the $s$th column of $\bar{A}$, or $\bar{A}_s$.

    The ith constraint is $x_1 + \bar{a}_{is} x_s + \mathcal{L} \text{ terms } =
    \bar{b}_i$.

    If $\bar{A}_{is} \leq 0 \: \forall i$ then x_s can be increased arbitrarily to.

    Assume \exists i s.t. $\bar{a}_{is} > 0

    \begin{equation}
      \theta = \min_{i: \bar{a}_{is} > 0} \frac{\bar{b}_i}{\bar{a}_{is}}
    \end{equation}

    Since $\bar{b}_i \ge 0$ and $\bar{a}_{is} > 0$, we can claim $\theta \ge 0$.
    However, we'll be doing the non-degenerate case, and assuming $\theta > 0$.

    More proof stuff that I really need to read about.

** Duality

   - Primal: min C^T x s.t. Ax \ge b, x \ge 0.
   - Dual: max b^T \pi s.t. A^T \pi \le c, \pi \ge 0

   Claim: dual of dual is primal.

   Theorem (Weak Duality): \forall feasible x, \pi, b^T \pi \le c^t x.
* 2015-09-09 Wednesday

** Linear Programming

   min c^T x, s.t. Ax = b, x \geq 0
   - A p \times q matrix.
   - Rank(A) = p
   - A = (A_1, A_2, A_3, ..., A_q)

   Let $\bar{x}$ be a feasible solution.  Let $A(\bar{x}) = \{A_i: \bar{x}_i >
   0\}$.  *Thm:* $\bar{x}$ is an extreme point iff $A(\bar{x})$ is a set of
   linearly independent vectors.

   *Def:* (B,L) is a basis structure iff:
   - (B,L) partition of {1, 2, ..., q}.
   - {A_I: i \in B} is a basis for R^p

   A = (B, L), x = (x_B, x_L), c = (c_B, c_L)

   EG: min x_1+x_2+x_3+x_4 s.
   - x_1 + 2x_2 + 3x_4 = 1
   - 4x_2 + x_3 + 2x_4 = 2
   - All x \geq 0

   Rename variables x_1 to y_1, x_2 to y_3, x_3 to y_2, x_4 to y_4:

   min y_1 + y_2 + y_3 + y_4, s.t.
   - y_1 + 2y_3 + 3y_4 = 1
   - y_2 + 4y_3 + 2y_4 = 2
   - All y \geq 0

   \begin{equation}
   A = \begin{bmatrix} 1 & 0 & 2 & 3 \\ 0 & 1 & 4 & 2 \end{bmatrix}
   \end{equation}

   The left half of A is B, and the right half is L.

   \begin{equation}
   y = \begin{bmatrix}y_1 \\ y_2 \\ y_3 \\ y_4 \end{bmatrix}
   \end{equation}
   \begin{equation}
   c = \begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}
   \end{equation}

   The top halves of these are $y_B$ and $c_B$ respectively.

   \begin{align*}
     B x_B + L x_L &= b \\
     x_B + B^{-1} L x_L &= B^{-1} b \\
     x_B + \bar{A} x_L &= \bar{b}
   \end{align*}

   Here we're letting $\bar{A} = B^{-1} L$ and $\bar{b} = B^{-1} b$.

   A basic solution is one where $\bar{x_B} = \bar{b}$, or $\bar{x_L} = 0$.  A
   feasible basic solution is one where $\bar{x_B} \geq 0$ as well.

   *Def:* Simplex multipliers corresponding to $(B,L)$:

   \begin{equation}
     \pi^T = c_B^T B^{-1}
   \end{equation}

   Let $\bar{x} = \begin{bmatrix}\bar{x_B} \\ \bar{x_L} \end{bmatrix}$ be BFS
   corresponding to (B, L).  The objective function at $\bar{x}$ is:

   \begin{align*}
     \begin{bmatrix} c_B^T & c_L^T \end{bmatrix}
     \begin{bmatrix} \bar{x_B} \\ \bar{x_L} \end{bmatrix}
     &= c_B^T \bar{x_B} + c_L^T x_L \\
     &= (\pi^T B) (B^{-1} b) + c_L^T (0) \\
     &= \pi^T b
   \end{align*}

   *Def:* Reduced costs corresponding to (B,L) = A

   \begin{equation}
     c^{\pi}  = c - A^T \pi
   \end{equation}

   \begin{equation}
     c^{\pi} = \begin{bmatrix} c_B^{\pi} \\ c_L^{\pi} \end{bmatrix}
     = \begin{bmatrix} c_B \\ c_L \end{bmatrix} - \begin{bmatrix} B^T & L^T \end{bmatrix} \pi
     = \begin{bmatrix} c_B - B^T \pi \\ c_L - L^T \pi \end{bmatrix}
     = \begin{bmatrix} 0 \\ c_L - L^T \pi \end{bmatrix}
   \end{equation}

   I guess you can also rewrite it to $c = c^{\pi} + A^T \pi$, but I'm not writing
   out the vectors and matrices again.  Now he's doing more stuff with the
   objective function.

   \begin{equation}
     c^T x = (c^{\pi}_L)^T x_L + \pi^T b
   \end{equation}

   Once we find the basic feasible solution, the $\pi^T b$ is pretty much fixed,
   and so we just need to minimize (C_L^{\pi})^T x_L.  Now, say we look at a non-basic
   (i.e. in L, not B) variable x_i, and look at its reduced costs.

   - If c_i^{\pi} \geq 0, we would be happy to set x_i = 0 (if it's feasible).
   - If c_i^{\pi} \lt 0, we would be happy to set x_i = +\infty (if it's feasible).

   We can see that if \forall i c_i^{\pi} \geq 0, then the BFS is optimal.  In fact, it's
   also true the other way around.

   *Thm:* BFS $\bar{x}$ is optimal iff \forall i c_i^{\pi} \geq 0.
   - Proof \leftarrow: (basically what we've been talking about)
   - Proof \to: is a really difficult, multi-lecture proof.  We'll sketch out the
     non-degenerate case only, \theta > 0.  Next time.
* 2015-09-02 Wednesday

** Review of LP

   - min C^T x, st.
   - Ax = b
   - x \geq 0

   Integer LP is same, except require that x is an integer.

*** Example

    Vertex Cover Problem - given a undirected graph G, find a vertex cover of
    minimum size.  (vc = a set of vertices that cover every edge).

    We are going to convert a VC problem into ILP.  The graph we have is (no
    diagrams, sorry): V={1, 2, 3, 4}, E={(1,2), (1,3), (1,4), (2,3), (3,4)}
    (undirected).

    Decision variables are x_i= 1, if i \in VC, 0 otherwise.  We minimize the
    function x_1 + x_2 + x_3 + x_4, s.t.:

    - x_1 + x_2 \geq 1
    - x_1 + x_3 \geq 1
    - x_1 + x_4 \geq 1
    - x_2 + x_3 \geq 1
    - x_3 + x_4 \geq 1
    - x_1, x_2, x_3, x_4 \in {0, 1}

    In case you can't tell, there is a constraint for each edge, which basically
    says that at least one of the vertices on the edge needs to be 1.

** Reducing Vertex Cover to ILP

   More generally, the vertex cover of G=(V,E) can be transformed to ILP like this:

   - Min \sum_{i\in{}V} x_i, s.t.
   - x_i + x_j \geq 1 \forall (i,j) \in E
   - x_i \in {0, 1} \forall i \in V

   When you remove the integrality constraint from an ILP, you get the *linear
   relaxation* of the problem.  In the case of this problem, we get an
   assignment of fractional weights to vertices such that each edge has sum \geq
   1, while minimizing the total vertex weights.  It's an entirely different
   problem, and not really something we want.

   According to the Liberator, the difference between a lot of the problems
   dealt with in other fields and in computer science is the addition of these
   "integrality constraints," which makes problems much more difficult than
   their continuous relatives.

** "Slicing" Linear Programs

   When you have the constraints Ax = b, you can think of it as a_i^T x = b_i,
   where a_i^T is a row vector of A.  This is totally linear algebra, and I'm sure
   it'll come in useful later in the course.

** Semi Definite Programming

   - *Def:* A real matrix A is positive (semi) definite iff \forall x \geq 0, x^T A x > 0
     (x^T A x \geq 0).

   - *Thm:* A is positive semidefinite iff all its eigenvalues are \geq 0.

   (note to self - go over linear algebra!)

   - *Def:* A is symmetric, positive, semidefinite -> A \succeq 0.

   - *Thm:* A \succeq 0 iff \exists B s.t. A = B^T B.  Given A, B can be found in polynomial
     time.  B is not necessarily square, but of course B^T B will be.

   - Given two matrices C, X (n by m), C \cdot X = \sum_{i=1}^n \sum_{j=1}^m c_ij x_ij.

   The problem of Semi Definite Programming is:

   - minimize C \cdot X, st:
   - A_i \cdot X = b_i
   - X \succeq 0

** LP reduces to SDP

   - *Claim:* Linear programming is a special case of (i.e. reduces to) Semi
     Definite Programming.

     \begin{equation}
     X = \begin{bmatrix} x_1 & 0 & 0 \\ 0 & \ddots & 0 \\ 0 & 0 & x_q \end{bmatrix}
     \end{equation}

     \begin{equation}
     C = \begin{bmatrix} c_1 & 0 & 0 \\ 0 & \ddots & 0 \\ 0 & 0 & c_q \end{bmatrix}
     \end{equation}

     \begin{equation}
     A_i = \begin{bmatrix} a_{i1} & 0 & 0 \\ 0 & \ddots & 0 \\ 0 & 0 & a_{iq} \end{bmatrix}
     \end{equation}

   - We wouldn't want to do this in practice, since we have more efficient
     algorithms to LP.  But it exists.

** Quadratically Constrained Quadratic Programming (QCQP)

   - min x^T Q x + q^T x
   - s.t. x^T Q_i x + q_i^T x \leq b_i, i=1,2,..,p

   Both the objective function and the constraints may be quadratic.

   - It seems that you can reduce QCQP also to SDP.
   - I guess the way to think about it is that in SDP, X = B^T B, so in the
     decision variables you get quadratic terms.  Or something.

** Back to Linear Programming

   Like you could slice LP constraint matrices by rows, you can also do it by
   columns.  Split A into columns A_1, A_2, ..., A_q.  Then, you can break the
   constraints into: A_1 x_1 + A_2 x_2 + ... + A_q x_q = b.

   Back when we were looking at LP the first time, we saw the feasible region as
   a polygon (or polyhedron), and the vertices were the extreme points, which
   are the candidate solutions.  These extreme points cannot be expressed as
   convex combination of other feasible solutions.  Even more exciting, *Thm:*
   All feasible solutions are convex combinations of extreme points.

   Each constraint point corresponds in some way to the column breakdown shown
   above, which allows us to do LP is a Linear Algebra way.

   *Thm:* A feasible solution is an extreme point iff:
   - A_i corresponding to x_i > 0 are independent.  That is, given a point x, look
     at its coordinates x_i, find the ones greater than 0, and check if the A_i
     corresponding to them are independent.
* 2015-08-31 Monday

** Linear Programming (LP)

   An instance of LP:

   - min \sum_{j=1}^q c_j x_j, subject to:
   - \sum_{j=1}^q a_{ij} x_j \leq b_i, for i = 1, 2, ..., p, and j=1, 2, ..., q
   - x_j > 0

   The constraints define X, the feasible region.  You can switch a minimization
   problem to a maximization problem by negating the objective function.
   Minimization is the "standard form".  You can also define the "slack
   variables" in the constraints, which were covered a bit more in the EECS 440
   lecture on LP.  EG, diet problem:

   | i | Food          | Energy | Protein | Calcium | Price | Max |   |   |   |   |   |   |   |
   | 1 | Oatmeal       |    110 |       4 |       2 |     3 |   4 |   |   |   |   |   |   |   |
   | 2 | Chicken       |    205 |      32 |      12 |    24 |   3 |   |   |   |   |   |   |   |
   | 3 | Eggs          |    160 |      13 |      54 |    13 |   2 |   |   |   |   |   |   |   |
   | 4 | Milk          |    160 |       8 |     285 |     9 |   8 |   |   |   |   |   |   |   |
   | 5 | Pie           |    420 |       4 |      22 |    20 |   2 |   |   |   |   |   |   |   |
   | 6 | Pork w/ beans |    260 |      14 |      80 |    19 |   2 |   |   |   |   |   |   |   |
   |   | GOALS         |   2000 |      55 |     800 |   min |     |   |   |   |   |   |   |   |

   Decision variable is x_1, so here is the problem:

   - minimize, 3x_1 + 24x_2 + 13x_3 + 9x_4 + 20x_5 + 19x_6, subject to:
   - 110x_1 + 205x_2 + 160x_3 + 160x_4 + 420x_5 + 260x_6 \geq 2000
   - 4x_1 + 32x_2 + 13x_3 + 8x_4 + 4x_5 + 14x_6 \geq 55
   - 2x_1 + 12x_2 + 54x_3 + 285x_4 + 22x_5 + 80x_6 \geq 800
   - 0 \leq x_1 \leq 4
   - 0 \leq x_2 \leq 3
   - 0 \leq x_3 \leq 2
   - 0 \leq x_4 \leq 8
   - 0 \leq x_5 \leq 2
   - 0 \leq x_6 \leq 2

   This isn't in standard form due to the greater than or equal to in the top 3
   constraints, and the less than or equal to in the variable bounds.  I guess.

   What to do to get decision variables unrestricted in sign (not in std form):
   If you want x to be negative (or just allowed to be negative) replace it with
   two variables (say, y and z).  Substitute x with y-z, and add the condition
   that y,z \geq 0.  This allows x (aka y-z) to be positive or negative, but you
   could add more conditions on y-z to make it how you'd like.

   The graphical representation of these problems is pretty simple (when you
   have two variables).  The constraints create a nice shaded polygon that
   represents your feasible region, and then you pick the vertex that maximizes
   the objective function.

   **Claim:** There is always an optimal solution in an extreme point.  That's
   worded weird.  I prefer "an optimal solution is always an extreme point."

   You can represent a LP instance in matrix form like this:
   - min C^T x
   - s.t. Ax=b
   - x \geq 0

   Where, x = (x_1, x_2, ..., x_q)^T, c = (c_1, c_2, ..., c_q)^T, A=(a_11, a_12, ..., a_1q;
   ...; a_p1, a_p2, ..., a_pq), b=(b_1, b_2, ..., b_p)^T.

** Integer Linear Programming

   Same as ^, except that the x's must be integers.  Since this is a more
   restricted problem, the solutions are no better than the LP solutions.

** Mixed Integer Linear Programming

   MILP.  Really?

   > Matrix I'd Like to Program - Andrew Mason

   Only some of the decision variables need to be integral, others can be
   continuous.

** Next Time, on Advanced Algorithms:

   Vertex cover, formulated as ILP.

* 2015-08-28 Friday

** Last Time:

   Approximation algorithms have approximation ratio:

   apx ratio = \(max_{I\in{}\mathscr{I}} {\frac{c(I)}{c^*(I)}}\)

   A c-approximation algorithm has cost \leq c \times optimal cost on all instances I of
   the problem $\mathscr{I}$.  One example is the vertex cover problem.  We
   covered a 2-approximation algorithm (called =VCapx=) that operates by
   repeatedly choosing an edge, adding its endpoints to the VC, and removing all
   incident edges from the graph.

   We left off saying that today we would cover the proof that it is a 2-apx
   algorithm.

** Proof

   *Theorem* =VCapx= is a 2-approximation algorithm.

   *Proof* Every edge is covered by =VCapx= at termination.  For every one of
   these edges, the algorithm adds at most two vertices to $V'$.  The optimal
   solution contains at least one of these two.  =VCapx= never considers the
   same vertex twice (since it deletes incident edges).  So, this is a 2
   approximation algorithm.

   Here's the actual text of his proof:

   - Every edge is covered by =VCapx= at terminates.
   - \forall edge chosen by =VCapx=
     - =VCapx= adds 2 vertices to $V'$
     - Opt contains at least one of the two vertices
   - =VCapx= never considers same vertex twice. (by deleting incident edges)
     - \to edges are disjoint, \to $V'$ can be partitioned by edges added by =VCapx=
   - \rightarrow 2-apx algorithm

** Reduction

   The pipeline of reduction:

   (X, c) \in *I* \to (X', c') \in *I' \to* x'^* \to x^*

   If the time to translate (X,c) to (X', c') is T_1, and the time to translate
   x'^* to x^* is T_2, then problem *I* reduces to *I^'* in time T_1 + T_2.

   EG: Any maximization problem reduces to a minimization problem in O(1) time.

***  Optimal Message Passing

     Given a graph G=(V,E) with probability p_e (0 < p_e < 1) associated to each e
     \in E.  Find a spanning tree of G that minimizes the probability of failure.
     (The probabilities are of failure, and independent).

     So, the probability of survival for the whole tree is \Pi_{e\in T} (1-p_e).

     We can reduce the OMP to Minimum Spanning Tree problem in linear time.  We
     define the weight of an edge to be w_e = -\log (1-p_e).  The cost of an MST
     is c(T) = \sum_{e\in T} w_e = \sum_{e\in T} \log 1/(1-p_e) = \log \Pi_{e\in T} 1/(1-p_e) =
     \log 1/(\Pi_{e\in T}(1-p_e)).  Since we're trying to minimize that logarithm, and
     logarithms are strictly increasing functions, we also are minimizing the
     inside of the logarithm.  This is the same as maximizing the denominator,
     which happens to be the probability of survival of the tree.

*** Choosing your reduction

    This isn't necessarily like EECS 343 reductions, where you find the easiest
    reduction to do.  There are entire families of problems that are special
    cases of each other.  A problem might be able to be reduced to the simplest
    of these, or the most general of these.  The reduction to the most general
    problem is usually easiest, and the reduction to the simpler problem is more
    difficult.  The advantage of doing the harder reduction is generally a
    faster algorithm to solve the simpler problem.  It's just a wonderful world
    of tradeoffs here in computer science land.

** GNU Octave

   - Download it via your package manager, or from the GNU website if you're a
     Win/Mac user.
   - There is a good deal of documentation on the GNU site about how to use
     Octave.  It looks like a less powerful Python+NumPy+Matplotlib, or maybe a
     less powerful (open source) Mathematica.
   - =glpk= function for linear programming.
   - First homework this afternoon, due in two weeks!
* TODO 2015-08-26 Wednesday

  Need to copy over notes from paper.
* 2015-08-24 Monday

  - 5 books, get sections from library
  - 2 tests:
    - Final exam, possibly oral.
    - Midterm
  - 6 homeworks:
    - Need to know octave

** Asymptotics

   Measure time complexity.  Focus is on large inputs.

   - f(n) \in O(g(n)) means "f(n) \leq g(n)"

     \exists c > g, n_0 > 0 s.t. \forall n \geq n_0 : f(n) \leq c g(n)

   - f(n) = \Omega(g(n)) defined: g(n) \in O(f(n))

   - f(n) \in \Theta(g(n)) defined: f(n) \in O(g(n)) and f(n) \in \Omega(g(n))

   - f(n) \in o(g(n)) defined: \(\lim_{n\to\infty} \frac{f(n)}{g(n)} = 0\)

   - f(n) \in \omega(g(n)) defined: \(\lim{n\to\infty} \frac{f(n)}{g(n)}
     =\infty\)

   What is $n$?  Input size.  Sometimes it's a number of elements, or it could
   be multiple parameters (number of nodes, number of edges).

   Sometimes we use the number of bits of the input.  For example, an algorithm
   with input integer $k$.  The number of bits is $n=\Theta(\log k)$.  If the
   runtime is $O(k)$, it looks like it's linear time.  But in the number of
   bits, it's exponential ($O(2^n)$).  It looks polynomial, but it's
   exponential.  It's called pseudo-polynomial.

   Formula:

   $(1-\frac{x}{k})^k$, where \(x \in R\), \(k \in N^+\).  We have that quantity
   \(< e^{-k}\), and \(\geq (1-x)\).  This will be used a lot apparently.

** Optimization Problems

   **Definition:** An instance of an optimization problem is a pair $(X,f)$,
     where $X$ is a set of feasible solutions, and $f$ is an objective function.
     $f$ maps from $X$ to the real numbers.  An /optimal solution/ $x^*$ is an
     element of $X$ with the property that \(f(x^*) \leq f(x) \: \forall x \in
     X\).

   For instance, if you have a graph and you're talking about the minimum
   spanning tree problem, $X$ is the set of all MSTs, and $f$ maps each to the
   sum of the edge weights in the tree.
